# Deep Q Network For BeerGame


• Implemented Q-learning with Deep Neural Networks to approximate Q-values,target network
to to provide steady Q-value predictions, experience replay buffer to stabilize and improve
the efficiency, and shaped reward to prioritize system-wide objectives over local ones
• Transfer learning is applied to reduce training time for different agents
• achieved near-optimal order quantities when playing with agents using base-stock policies
and surpassed base-stock policies with Sterman co-players.

 Incorporated code from Afshin Oroojlooy’s repository, accessible at github, for my research.
Initially, encountering this repository was both exciting and challenging.
The provided code did not function as intended at first, prompting me to deeply understand and enhance its functionality and made several
enhancements and modifications.
This repository hosts the refined version of the code with enhancements to ensure its operational integrity for scholarly or developmental pursuits.

enhancements and modifications. 

Supervisor: Prof.Erfan Hassannaebi
main reference: https://doi.org/10.48550/arXiv.1708.05924

